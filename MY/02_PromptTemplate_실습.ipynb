{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "TNQmGkXzI9tM"
      },
      "outputs": [],
      "source": [
        "# !pip install langchain\n",
        "# !pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install langchain_community"
      ],
      "metadata": {
        "id": "hi9uYU3VKYQX"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pip install openai==0.28.0"
      ],
      "metadata": {
        "id": "OuAJ2wO8Rcku"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "from langchain.llms import OpenAI\n",
        "\n",
        "from langchain.chat_models import ChatOpenAI"
      ],
      "metadata": {
        "id": "34LidWwJKCFx"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import openai\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"api key ì…ë ¥\""
      ],
      "metadata": {
        "id": "vGRD_4PgKCCB"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "davinch3 = OpenAI(\n",
        "    model_name=\"text-davinci-003\",\n",
        "    max_tokens = 1000\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_IEuoQ41aK1y",
        "outputId": "8192b3be-d4f7-4459-af64-d7917fea18c5"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAI`.\n",
            "  warn_deprecated(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chatgpt = OpenAI(\n",
        "    model_name = 'gpt-3.5-turbo',\n",
        "    max_tokens = 1000\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-QRgnsw9M-Gz",
        "outputId": "d7abcb61-31c1-4037-afd2-ab9350286f6f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_community/llms/openai.py:253: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain_community.chat_models import ChatOpenAI`\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_community/llms/openai.py:1076: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain_community.chat_models import ChatOpenAI`\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## í”„ë¡¬í”„íŠ¸ íƒ¬í”Œë¦¿ì€ í¬ê²Œ 2ê°€ì§€ê°€ ì¡´ì¬\n",
        "\n",
        "1. Prompt Template\n",
        "2. Chat Prompt Template\n",
        "\n",
        "- Prompt Template : ì¼ë°˜ì ì¸ í”„ë¡¬í”„íŠ¸ í…œí”Œë«ì„ ìƒì„±í• ë•Œ í™œìš©\n",
        "- Chat Prompt Template : ì±„íŒ… LLMì— í”„ë¡¬í”„íŠ¸ë¥¼ ì „ë‹¬í•˜ëŠ” ë°ì— í™œìš©í•  ìˆ˜ ìˆëŠ” íŠ¹í™” í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿"
      ],
      "metadata": {
        "id": "GwfnbtMSNHrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prompt Template"
      ],
      "metadata": {
        "id": "n9KOtSNiOW2P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate, ChatPromptTemplate\n",
        "\n",
        "#í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì„ í†µí•´ ë§¤ê°œë³€ìˆ˜ ì‚½ì…ì´ ê°€ëŠ¥í•œ ë¬¸ìì—´ë¡œ ë°˜í™˜\n",
        "string_prompt = PromptTemplate.from_template(\"tell me a joke about {subject}\")\n",
        "\n",
        "#ë§¤ê°œë³€ìˆ˜ ì‚½ì…í•œ ê²°ê³¼ë¥¼ string_prompt_valueì— í• ë‹¹\n",
        "string_prompt_value = string_prompt.format_prompt(subject = 'soccer')\n",
        "\n",
        "#ì±„íŒ… LLMì´ ì•„ë‹Œ LLMê³¼ ëŒ€í™”í•  ë•Œ í•„ìš”í•œ í”„ë¡¬í”„íŠ¸ = string_prompt\n",
        "string_prompt_value"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aijcN0eFK_dO",
        "outputId": "3a6006bf-5efe-4bc4-d695-a63819e89241"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StringPromptValue(text='tell me a joke about soccer')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#to_string() í•¨ìˆ ë¥´ í†µí•´ prompt templateë¡œ ìƒì„±í•œ ë¬¸ì ë°˜í™˜\n",
        "string_prompt_value.to_string()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "3z-yClchOD-V",
        "outputId": "983a3834-36bd-4ef0-9458-a7f087a0664a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'tell me a joke about soccer'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ChatPromptTemplate"
      ],
      "metadata": {
        "id": "K19_8RbOOZhW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chat_prompt = ChatPromptTemplate.from_template(\"tell me a joke about {subject}\")\n",
        "chat_prompt_value = chat_prompt.format_prompt(subject = 'soccer')\n",
        "chat_prompt_value\n",
        "\n",
        "#ì‚¬ìš©ìê°€ ë³´ë‚´ëŠ” ë©”ì‹œì§€ë¡œ ë‚˜ì˜´"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZKKm8cWOKXd",
        "outputId": "e8b7b47d-1a33-4e12-b8d7-5436c547f619"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatPromptValue(messages=[HumanMessage(content='tell me a joke about soccer')])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat_prompt_value.to_string()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "BoAcer-6OtLU",
        "outputId": "47c98448-02e6-4e89-e623-fb9692bc1578"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Human: tell me a joke about soccer'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ í™œìš©í•´ë³´ê¸°\n",
        "\n",
        "### ë°˜ë³µì ì¸ í”„ë¡¬í”„íŠ¸ë¥¼ ì‚½ì…í•´ì•¼ í•˜ëŠ” ê²½ìš°, Prompt Templateë¥¼ í†µí•´ ê°„í¸í•˜ê²Œ LLMì„ í™œìš©í•  ìˆ˜ ìˆë‹¤.\n",
        "\n",
        "- GPT-3.5ì™€ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì„ í™œìš©í•˜ì—¬ ëŒ€í™”í•´ë³´ê¸°"
      ],
      "metadata": {
        "id": "b2R1RV4PO8oS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts.prompt import PromptTemplate\n",
        "\n",
        "template = \"\"\"\n",
        "ë„ˆëŠ” ìš”ë¦¬ì‚¬ì•¼. ë‚´ê°€ ê°€ì§„ ì¬ë£Œë“¤ì„ ê°€ì§€ê³  ë§Œë“¤ ìˆ˜ ìˆëŠ” ìš”ë¦¬ë¥¼ ì¶”ì²œí•˜ê³ , ê·¸ ìš”ë¦¬ì˜ ë ˆì‹œí”¼ë¥¼ ì œì‹œí•´ì¤˜.\n",
        "ë‚´ê°€ ê°€ì§„ ì¬ë£ŒëŠ” ì•„ë˜ì™€ ê°™ì•„.\n",
        "\n",
        "<ì¬ë£Œ>\n",
        "{ì¬ë£Œ}\n",
        "\n",
        "\"\"\"\n",
        "prompt_template = PromptTemplate(\n",
        "    input_variables = ['ì¬ë£Œ'],\n",
        "    template = template\n",
        ")"
      ],
      "metadata": {
        "id": "MfR3JR_BO0Xv"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(prompt_template.format(ì¬ë£Œ = 'ì–‘íŒŒ, ê³„ë€, ì‚¬ê³¼, ë¹µ'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "skx2xqlyO0VC",
        "outputId": "82624ead-2c97-4ad4-a94a-9e3504495dd7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ë„ˆëŠ” ìš”ë¦¬ì‚¬ì•¼. ë‚´ê°€ ê°€ì§„ ì¬ë£Œë“¤ì„ ê°€ì§€ê³  ë§Œë“¤ ìˆ˜ ìˆëŠ” ìš”ë¦¬ë¥¼ ì¶”ì²œí•˜ê³ , ê·¸ ìš”ë¦¬ì˜ ë ˆì‹œí”¼ë¥¼ ì œì‹œí•´ì¤˜.\n",
            "ë‚´ê°€ ê°€ì§„ ì¬ë£ŒëŠ” ì•„ë˜ì™€ ê°™ì•„. \n",
            "\n",
            "<ì¬ë£Œ>\n",
            "ì–‘íŒŒ, ê³„ë€, ì‚¬ê³¼, ë¹µ\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(chatgpt(\n",
        "    prompt_template.format(ì¬ë£Œ = 'ì–‘íŒŒ, ê³„ë€, ì‚¬ê³¼, ë¹µ')\n",
        "))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ftV9vnDTO0Sn",
        "outputId": "4451c225-9aff-4536-d1b1-7e3f354aecec"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The method `BaseLLM.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 0.3.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ì œê°€ ì¶”ì²œí•˜ëŠ” ìš”ë¦¬ëŠ” \"ì–‘íŒŒ ê³„ë€ ë§ì´\" ì…ë‹ˆë‹¤. \n",
            "\n",
            "[ì–‘íŒŒ ê³„ë€ ë§ì´ ë ˆì‹œí”¼]\n",
            "ì¬ë£Œ:\n",
            "- ì–‘íŒŒ 1ê°œ\n",
            "- ê³„ë€ 2ê°œ\n",
            "- ì†Œê¸ˆ 1/2 ì‘ì€ìˆ \n",
            "- í›„ì¶” ì•½ê°„\n",
            "\n",
            "1. ì–‘íŒŒë¥¼ ì–‡ê²Œ ì±„ì°ì–´ ì¤€ë¹„í•©ë‹ˆë‹¤.\n",
            "2. ê³„ë€ì„ ê·¸ë¦‡ì— ê¹¨ê³  ì†Œê¸ˆê³¼ í›„ì¶”ë¥¼ ë„£ê³  í‘¼ í›„ì— ì–‘íŒŒë¥¼ ë„£ì–´ ì„ì–´ì¤ë‹ˆë‹¤. \n",
            "3. íŒ¬ì— ì‹ìš©ìœ ë¥¼ ë‘ë¥´ê³  ì–‘íŒŒ ê³„ë€ì„ ë¶€ì–´ ì˜ ìµí˜€ì¤ë‹ˆë‹¤. \n",
            "4. ë¶ˆì„ ë„ê³  ì™„ì„±ëœ ìš”ë¦¬ ìœ„ì— ê¹¨ë—í•œ ë¹µì„ ê³ë“¤ì—¬ ë°œë¼ ë¨¹ìŠµë‹ˆë‹¤. \n",
            "\n",
            "ë§›ìˆê²Œ ì¦ê¸°ì„¸ìš”! ğŸ˜Š\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- ChatGPTì™€ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì„ í™œìš©í•˜ì—¬ ëŒ€í™”í•´ë³´ê¸°"
      ],
      "metadata": {
        "id": "Lv7w_lb8Rn4L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import (ChatPromptTemplate, PromptTemplate, SystemMessagePromptTemplate,\n",
        "                              AIMessagePromptTemplate, HumanMessagePromptTemplate)\n",
        "from langchain.schema import (\n",
        "    AIMessage,\n",
        "    HumanMessage,\n",
        "    SystemMessage\n",
        ")"
      ],
      "metadata": {
        "id": "sFP4IXisRq5V"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#chatgpt ëª¨ë¸ ë¡œë“œ\n",
        "chatgpt = ChatOpenAI(temperature=0)\n",
        "\n",
        "#chatgptì—ê²Œ ì—­í•  ë¶€ì—¬\n",
        "system_message_prompt = SystemMessagePromptTemplate.from_template(template)\n",
        "\n",
        "#ì‚¬ìš©ìê°€ ì…ë ¥í•  ë§¤ê°œë³€ìˆ˜ templateì„ ì„ ì–¸\n",
        "human_template = \"{ì¬ë£Œ}\"\n",
        "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
        "\n",
        "#ChatPromptTemplateì— system messageì™€ human message í…œí”Œë¦¿ì„ ì‚½ì…\n",
        "chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
        "\n",
        "answer = chatgpt(chat_prompt.format_prompt(ì¬ë£Œ = 'ì–‘íŒŒ, ê³„ë€, ì‚¬ê³¼, ë¹µ').to_messages())\n",
        "print(answer.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j-9aEKG0R4A5",
        "outputId": "b6987774-0a73-442a-8fb7-b8b89871740e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
            "  warn_deprecated(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The method `BaseChatModel.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 0.3.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ì œê°€ ì¶”ì²œí•˜ëŠ” ìš”ë¦¬ëŠ” \"ì–‘íŒŒ ê³„ë€ í† ìŠ¤íŠ¸\"ì…ë‹ˆë‹¤. ë§›ìˆê³  ê°„ë‹¨í•˜ê²Œ ë§Œë“¤ ìˆ˜ ìˆëŠ” ìš”ë¦¬ì—ìš”. \n",
            "\n",
            "**ì–‘íŒŒ ê³„ë€ í† ìŠ¤íŠ¸ ë ˆì‹œí”¼:**\n",
            "\n",
            "**ì¬ë£Œ:**\n",
            "- ì–‘íŒŒ\n",
            "- ê³„ë€\n",
            "- ë¹µ\n",
            "- ì†Œê¸ˆ\n",
            "- í›„ì¶”\n",
            "- ì‹ìš©ìœ \n",
            "\n",
            "**ë§Œë“œëŠ” ë²•:**\n",
            "1. ì–‘íŒŒë¥¼ ì–‡ê²Œ ìŠ¬ë¼ì´ìŠ¤í•´ì¤ë‹ˆë‹¤.\n",
            "2. íŒ¬ì— ì‹ìš©ìœ ë¥¼ ë‘ë¥´ê³  ì–‘íŒŒë¥¼ ë³¶ì•„ íˆ¬ëª…í•´ì§ˆ ë•Œê¹Œì§€ ë³¶ì•„ì¤ë‹ˆë‹¤.\n",
            "3. ë³¶ì€ ì–‘íŒŒì— ì†Œê¸ˆê³¼ í›„ì¶”ë¥¼ ë„£ê³  ë³¶ì•„ì¤ë‹ˆë‹¤.\n",
            "4. ê³„ë€ì„ í’€ì–´ ì†Œê¸ˆì„ ì•½ê°„ ë„£ê³  í‘¸ì§í•˜ê²Œ í’€ì–´ì¤ë‹ˆë‹¤.\n",
            "5. ë‹¤ë¥¸ íŒ¬ì— ì‹ìš©ìœ ë¥¼ ë‘ë¥´ê³  ê³„ë€ì„ ë¶€ì¹©ë‹ˆë‹¤.\n",
            "6. ê³„ë€ì´ ìµìœ¼ë©´ ì–‘íŒŒì™€ ì„ì–´ì¤ë‹ˆë‹¤.\n",
            "7. ë¹µì„ êµ½ê±°ë‚˜ í† ìŠ¤í„°ì— êµ¬ì›Œì„œ ë°”ì‚­í•˜ê²Œ êµ¬ì›Œì¤ë‹ˆë‹¤.\n",
            "8. ë°”ì‚­í•œ ë¹µ ìœ„ì— ì–‘íŒŒì™€ ê³„ë€ì„ ì˜¬ë ¤ì¤ë‹ˆë‹¤.\n",
            "\n",
            "ë§›ìˆëŠ” ì–‘íŒŒ ê³„ë€ í† ìŠ¤íŠ¸ê°€ ì™„ì„±ë˜ì—ˆì–´ìš”. ë§›ìˆê²Œ ì¦ê¸°ì„¸ìš”!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Few-Shot ì˜ˆì œë¥¼ í†µí•œ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿\n",
        "\n",
        "- Few-Shotì´ë€, ë”¥ëŸ¬ë‹ ëª¨ë¸ì´ ê²°ê³¼ë¬¼ì„ ì¶œë ¥í•  ë•Œ ì˜ˆì‹œ ê²°ê³¼ë¬¼ì„ ì œì‹œí•¨ìœ¼ë¡œì¨ ì›í•˜ëŠ” ê²°ê³¼ë¬¼ë¡œ ìœ ë„í•˜ëŠ” ë°©ë²•ë¡ \n",
        "- LLMì—­ì‹œ, Few-Shotì˜ˆì œë¥¼ ì œê³µí•˜ë©´ ì˜ˆì œì™€ ìœ ì‚¬í•œ í˜•íƒœì˜ ê²°ê³¼ë¬¼ì„ ì¶œë ¥\n",
        "\n",
        "- ë‚´ê°€ ì›í•˜ëŠ” ê²°ê³¼ë¬¼ì˜ í˜•íƒœê°€ íŠ¹ìˆ˜í•˜ê±°ë‚˜, êµ¬ì¡°í™”ëœ ë‹µë³€ì„ ì›í•  ê²½ìš°, ê²°ê³¼ë¬¼ì˜ ì˜ˆì‹œë¥¼ ìˆ˜ ê°œ ì œì‹œí•¨ìœ¼ë¡œì¨ ê²°ê³¼ë¬¼ì˜ í’ˆì§ˆì„ í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆë‹¤"
      ],
      "metadata": {
        "id": "UJr6TpY0Wxh8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
        "from langchain.prompts.prompt import PromptTemplate\n",
        "\n",
        "examples = [\n",
        "    {\n",
        "        \"question\" : 'ì—ìŠ¤íŒŒë¡œ ì‚¼í–‰ì‹œ ë§Œë“¤ì–´ì¤˜',\n",
        "        \"answer\" :\n",
        "\"\"\"\n",
        "ì— : ì—ë¼ì´\n",
        "ìŠ¤ : ìŠ¤íŒŒê²Œí‹°ì—\n",
        "íŒŒ : íŒŒë¥¼ ë„ˆë¬´ ë§ì´ ë„£ì—ˆì–´.\n",
        "\"\"\"\n",
        "    },\n",
        "    {\n",
        "       \"question\" : 'ì´ì˜ˆì§„ìœ¼ë¡œ ì‚¼í–‰ì‹œ ë§Œë“¤ì–´ì¤˜',\n",
        "        \"answer\" :\n",
        "\"\"\"\n",
        "ì´ : ì´ê²ƒ ì¢€ ë´ë°”\n",
        "ì˜ˆ : ì˜ˆìƒë„ ëª»í–ˆì–´\n",
        "ì§„ : ì§„ì§œ\n",
        "\"\"\"\n",
        "    }\n",
        "]"
      ],
      "metadata": {
        "id": "9-YrVKgsS_ni"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_prompt = PromptTemplate(input_variables = [\"question\", \"answer\"], template = \"Question: : {question}\\n{answer}\")\n",
        "\n",
        "print(example_prompt.format(**examples[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UNReojvgYood",
        "outputId": "1e0e305f-4794-4107-a5d3-c10658b92b1f"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: : ì—ìŠ¤íŒŒë¡œ ì‚¼í–‰ì‹œ ë§Œë“¤ì–´ì¤˜\n",
            "\n",
            "ì— : ì—ë¼ì´\n",
            "ìŠ¤ : ìŠ¤íŒŒê²Œí‹°ì— \n",
            "íŒŒ : íŒŒë¥¼ ë„ˆë¬´ ë§ì´ ë„£ì—ˆì–´.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = FewShotPromptTemplate(\n",
        "    examples = examples, #ì¶œë ¥\n",
        "    example_prompt = example_prompt,\n",
        "    suffix = \"Question : {input}\",\n",
        "    input_variables = [\"input\"]\n",
        ")\n",
        "\n",
        "print(prompt.format(input = 'í˜¸ë‚ ë‘ìœ¼ë¡œ ì‚¼í–‰ì‹œ ë§Œë“¤ì–´ì¤˜'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4tVcl8bmY3YI",
        "outputId": "54fb7ddc-c05d-4d20-b5fc-23353c4fea25"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: : ì—ìŠ¤íŒŒë¡œ ì‚¼í–‰ì‹œ ë§Œë“¤ì–´ì¤˜\n",
            "\n",
            "ì— : ì—ë¼ì´\n",
            "ìŠ¤ : ìŠ¤íŒŒê²Œí‹°ì— \n",
            "íŒŒ : íŒŒë¥¼ ë„ˆë¬´ ë§ì´ ë„£ì—ˆì–´.\n",
            "\n",
            "\n",
            "Question: : ì´ì˜ˆì§„ìœ¼ë¡œ ì‚¼í–‰ì‹œ ë§Œë“¤ì–´ì¤˜\n",
            "\n",
            "ì´ : ì´ê²ƒ ì¢€ ë´ë°” \n",
            "ì˜ˆ : ì˜ˆìƒë„ ëª»í–ˆì–´\n",
            "ì§„ : ì§„ì§œ\n",
            "\n",
            "\n",
            "Question : í˜¸ë‚ ë‘ìœ¼ë¡œ ì‚¼í–‰ì‹œ ë§Œë“¤ì–´ì¤˜\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(chatgpt.predict(\"í˜¸ë‚ ë‘ìœ¼ë¡œ ì‚¼í–‰ì‹œ ë§Œë“¤ì–´ì¤˜\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cLw9LOrqZhI7",
        "outputId": "f61a061d-d2f0-47a1-a1fe-c51c492ec0b1"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "í˜¸ë‚ ë‘ê°€ ë›°ì–´ë‹¤ë‹ˆë©°\n",
            "ê³µì„ ì°¨ê³  ë†€ì•„ìš”\n",
            "ì¶•êµ¬ì™•ì´ ë˜ë¦¬ë¼\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(davinch3(\n",
        "    prompt.format(input = \"í˜¸ë‚ ë‘ë¡œ ì‚¼í–‰ì‹œ ë§Œë“¤ì–´ì¤˜\")\n",
        "))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "id": "E8tGeMupZhHA",
        "outputId": "213ae99e-439e-4bb7-dd32-35bc49f3d3c1"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "error",
          "ename": "InvalidRequestError",
          "evalue": "The model `text-davinci-003` has been deprecated, learn more here: https://platform.openai.com/docs/deprecations",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-a4f39ee48fd6>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m print(davinch3(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprompt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"í˜¸ë‚ ë‘ë¡œ ì‚¼í–‰ì‹œ ë§Œë“¤ì–´ì¤˜\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m ))\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py\u001b[0m in \u001b[0;36mwarning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    166\u001b[0m                 \u001b[0mwarned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m                 \u001b[0memit_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mawarning_emitting_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, prompt, stop, callbacks, tags, metadata, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m             )\n\u001b[1;32m   1191\u001b[0m         return (\n\u001b[0;32m-> 1192\u001b[0;31m             self.generate(\n\u001b[0m\u001b[1;32m   1193\u001b[0m                 \u001b[0;34m[\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1194\u001b[0m                 \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, prompts, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    880\u001b[0m                 )\n\u001b[1;32m    881\u001b[0m             ]\n\u001b[0;32m--> 882\u001b[0;31m             output = self._generate_helper(\n\u001b[0m\u001b[1;32m    883\u001b[0m                 \u001b[0mprompts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_managers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36m_generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    738\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mrun_manager\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrun_managers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m                 \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_llm_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLLMResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m         \u001b[0mflattened_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmanager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflattened_output\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_managers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflattened_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36m_generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m             output = (\n\u001b[0;32m--> 727\u001b[0;31m                 self._generate(\n\u001b[0m\u001b[1;32m    728\u001b[0m                     \u001b[0mprompts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m                     \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_community/llms/openai.py\u001b[0m in \u001b[0;36m_generate\u001b[0;34m(self, prompts, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    462\u001b[0m                 )\n\u001b[1;32m    463\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 464\u001b[0;31m                 response = completion_with_retry(\n\u001b[0m\u001b[1;32m    465\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_prompts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_community/llms/openai.py\u001b[0m in \u001b[0;36mcompletion_with_retry\u001b[0;34m(llm, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mllm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_completion_with_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36mwrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0mcopy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m             \u001b[0mwrapped_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatistics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatistics\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mretry_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mWrappedFn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    473\u001b[0m         \u001b[0mretry_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRetryCallState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry_object\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m             \u001b[0mdo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDoAttempt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36miter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    374\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maction\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(rs)\u001b[0m\n\u001b[1;32m    396\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_post_retry_check_actions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretry_state\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"RetryCallState\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_explicit_retry\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretry_run_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 398\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_action_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mrs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutcome\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    399\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    449\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m                 \u001b[0;31m# Break a reference cycle with the exception in self._exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    476\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDoAttempt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 478\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    479\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# noqa: B902\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m                     \u001b[0mretry_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_community/llms/openai.py\u001b[0m in \u001b[0;36m_completion_with_retry\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mretry_decorator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_completion_with_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mllm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_completion_with_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_resources/completion.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTryAgain\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_resources/abstract/engine_api_resource.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    151\u001b[0m         )\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         response, _, api_key = requestor.request(\n\u001b[0m\u001b[1;32m    154\u001b[0m             \u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0mrequest_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m         )\n\u001b[0;32m--> 298\u001b[0;31m         \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interpret_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    698\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m             return (\n\u001b[0;32m--> 700\u001b[0;31m                 self._interpret_response_line(\n\u001b[0m\u001b[1;32m    701\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0mstream_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstream\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"error\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstream_error\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mrcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m             raise self.handle_error_response(\n\u001b[0m\u001b[1;32m    766\u001b[0m                 \u001b[0mrbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m             )\n",
            "\u001b[0;31mInvalidRequestError\u001b[0m: The model `text-davinci-003` has been deprecated, learn more here: https://platform.openai.com/docs/deprecations"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "text-davinci-003 ëª¨ë¸ ì§€ì› x"
      ],
      "metadata": {
        "id": "Tc5WDTyRcJbM"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XDnwZL-zZ2gu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}