{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "라이브러리 설치"
      ],
      "metadata": {
        "id": "oIhX7VOLxghq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FCQMJZqQxbfp",
        "outputId": "9b1c0092-23ab-4949-8e99-0e0d927cda19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m990.6/990.6 kB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m61.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m384.0/384.0 kB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.2/140.2 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m360.7/360.7 kB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q langchain langchain-openai tiktoken"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "OpenAI 인증키 설정"
      ],
      "metadata": {
        "id": "RnEQcSKkyb0A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "import openai\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('')\n"
      ],
      "metadata": {
        "id": "gGbG9RsRyC8D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LLM Chain"
      ],
      "metadata": {
        "id": "fY4VDbKMyd0q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1) prompt+LLM"
      ],
      "metadata": {
        "id": "RgIn9ou_yg_o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "#model\n",
        "llm = ChatOpenAI(model = 'gpt-3.5-turbo-0125')\n",
        "\n",
        "#chain 설정\n",
        "content = llm.invoke(\"지구의 자전 주기는?\")\n",
        "content.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "PjTOzsehxqgf",
        "outputId": "ee735d71-62e4-4bb5-bdc8-5ef1348a1cb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'지구의 자전 주기는 약 24시간으로, 하루에 한 번 지구가 자전하면서 자신의 축 주위를 한 바퀴 회전합니다.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "#prompt + model + output parser\n",
        "prompt = ChatPromptTemplate.from_template(\"You are an expert in astronomy. Answer the question. <Question>: {input}\")\n",
        "llm = ChatOpenAI(model = 'gpt-3.5-turbo-0125')\n",
        "output_parser = StrOutputParser() #aimessage안의 text만 출력\n",
        "\n",
        "#chain 설정\n",
        "chain = prompt | llm | output_parser\n",
        "\n",
        "#chain 호출\n",
        "chain.invoke({\"input\": \"지구의 자전 주기는?\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "-0NsjXR5y8p6",
        "outputId": "3cfc92be-2a5c-4e9e-e920-fda38629f995"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'지구의 자전 주기는 약 24시간입니다. 이는 지구가 자전하는데 걸리는 시간을 의미하며, 이로 인해 하루가 낮과 밤으로 나뉘게 됩니다.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2)Multiple Chains"
      ],
      "metadata": {
        "id": "uhcXW3OE1DEM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#chain 2개 연결\n",
        "#prompt1 : 한국어단어를 영어로 번역\n",
        "#prompt2 : 영어단어에 대해 설명해라\n",
        "prompt1 = ChatPromptTemplate.from_template(\"translates {korean_word} to English.\")\n",
        "prompt2 = ChatPromptTemplate.from_template(\"explain {english_word} using oxford dictionary to me in Korean.\")\n",
        "\n",
        "llm = ChatOpenAI(model = 'gpt-3.5-turbo-0125')\n",
        "\n",
        "chain1 = prompt1 | llm | output_parser\n",
        "chain1.invoke({\"korean_word\":\"미래\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "YtS55Sssz4LZ",
        "outputId": "5df111ac-d004-476c-f239-139268a81b85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Future'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain2 = (\n",
        "    {\"english_word\" : chain1} | prompt2 | llm | output_parser\n",
        ")\n",
        "#chain1 >> Future\n",
        "chain2.invoke({'korean_word' : \"미래\"}\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "Q0lBWS0J1pa3",
        "outputId": "856bff5f-b025-476d-c94c-622f1e52ee64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'미래는 \"future\"라는 단어로 영어로 정의됩니다. \"미래\"란 어떤 일이나 사건이 발생할 때 일어날 것으로 예상되는 시간적인 범위를 가리킵니다. 일반적으로 미래는 현재 시간 이후의 시간을 의미하며, 미래에는 다양한 가능성과 전망이 포함될 수 있습니다.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Prompt"
      ],
      "metadata": {
        "id": "y_rMEryx20Oo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1) PromptTemplate\n",
        "\n",
        "- PromptTemplate + LLMs (단일 문장 입력 -> 단일 문장 출력)\n",
        "- **문자열 프롬프트**를 위한 템플릿을 생성. Python의 문자열 포맷팅 구문을 사용.\n",
        "- 내용:지시사항, 몇가지 예시, 특정 맥락 및 질문 등"
      ],
      "metadata": {
        "id": "3TSdE21b22AB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "# 'name'과 'age'라는 두 개의 변수를 사용하는 프롬프트 템플릿을 정의\n",
        "template_text = \"안녕하세요, 제 이름은 {name}이고, 나이는 {age}살입니다.\"\n",
        "\n",
        "# PromptTemplate 인스턴스를 생성\n",
        "prompt_template = PromptTemplate.from_template(template_text)\n",
        "\n",
        "# 템플릿에 값을 채워서 프롬프트를 완성\n",
        "filled_prompt = prompt_template.format(name='홍길동', age = 30 )\n",
        "\n",
        "filled_prompt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "yGm6XMco19ws",
        "outputId": "a962508c-0fde-47d4-b26e-1b28445fa522"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'안녕하세요, 제 이름은 홍길동이고, 나이는 30살입니다.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 문자열 템플릿 결합 (PromptTemplate + PromptTemplate + 문자열)\n",
        "combined_prompt = (\n",
        "    prompt_template +\n",
        "    PromptTemplate.from_template('\\n\\n아버지를 아버지라 부를 수 없습니다.') +\n",
        "    \"\\n\\n{language}로 번역해주세요.\"\n",
        ")\n",
        "combined_prompt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KQcadYD24Bhr",
        "outputId": "5911e7c7-65e5-48b0-d640-b2584181ab92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PromptTemplate(input_variables=['age', 'language', 'name'], template='안녕하세요, 제 이름은 {name}이고, 나이는 {age}살입니다.\\n\\n아버지를 아버지라 부를 수 없습니다.\\n\\n{language}로 번역해주세요.')"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "combined_prompt.format(name='홍길동', age = 30, language = '영어')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "AGpWlF8B4RNd",
        "outputId": "1f47835c-6983-4d8c-f2f0-0a6f5210f9be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'안녕하세요, 제 이름은 홍길동이고, 나이는 30살입니다.\\n\\n아버지를 아버지라 부를 수 없습니다.\\n\\n영어로 번역해주세요.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "llm = ChatOpenAI(model = 'gpt-3.5-turbo-0125')\n",
        "chain = combined_prompt | llm | output_parser\n",
        "\n",
        "chain.invoke({'name':'홍길동', 'age':30, 'language':'영어'})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "CWsfngRP4qCN",
        "outputId": "c2e3ac8b-b930-4a1a-8a7c-cba50da2244c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Hello, my name is Hong Gildong and I am 30 years old.\\n\\nI cannot call my father as father.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2)ChatPromptTemplate"
      ],
      "metadata": {
        "id": "HvQEiE5V5D6J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- ChatPromptTemplate + ChatModels (여러 메시지 입력 -> 단일 메시지 출력)\n",
        "- 채팅 메시지를 원소로 갖는 리스트 형태\n",
        "- 구성 : 각 채팅 메시지는 역할(role)과 내용(content)이 짝을 이루는 형태\n",
        "  - 예시 : OpenAI는 AI Assistant, Human, System등의 역할(role)로 구성"
      ],
      "metadata": {
        "id": "ChYMgM695azn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2-튜플 형태의 메시지 목록으로 프롬프트 생성 (type, content)\n",
        "\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "chat_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"이 시스템은 천문학 질문에 답변할 수 있습니다.\"),\n",
        "    (\"user\", \"{user_input}\"),\n",
        "])\n",
        "\n",
        "messages = chat_prompt.format_messages(user_input = \"태양계에서 가장 큰 행성은 무엇인가요?\")\n",
        "messages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDbOgXES5FyG",
        "outputId": "eab76277-85f1-4eed-bfde-69a4460b27f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[SystemMessage(content='이 시스템은 천문학 질문에 답변할 수 있습니다.'),\n",
              " HumanMessage(content='태양계에서 가장 큰 행성은 무엇인가요?')]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain = chat_prompt | llm | output_parser\n",
        "chain.invoke({'user_input':'태양계에서 가장 큰 행성은 무엇인가요?'})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "4D_AQGas6SZy",
        "outputId": "63548924-c89e-4942-f0a1-8d527ce444a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'태양계에서 가장 큰 행성은 목성입니다. 목성은 지름이 약 139,822km로 태양계에서 가장 큰 행성이며, 질량도 가장 큽니다.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3)Message"
      ],
      "metadata": {
        "id": "oMPRd6d-7U3Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# MessagePromptTemplate 활용\n",
        "\n",
        "from langchain_core.prompts import SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
        "\n",
        "chat_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        SystemMessagePromptTemplate.from_template(\"이 시스템은 천문학 질문에 답변할 수 있습니다.\"),\n",
        "        HumanMessagePromptTemplate.from_template(\"{user_input}\")\n",
        "    ]\n",
        ")\n",
        "\n",
        "messages = chat_prompt.format_messages(user_input = \"태양계에서 가장 큰 행성은 무엇인가요?\")\n",
        "messages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E2uW9P0E6SYD",
        "outputId": "34339710-773e-4881-ac24-0bd0de8517d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[SystemMessage(content='이 시스템은 천문학 질문에 답변할 수 있습니다.'),\n",
              " HumanMessage(content='태양계에서 가장 큰 행성은 무엇인가요?')]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain = chat_prompt | llm | output_parser\n",
        "chain.invoke({'user_input':'태양계에서 가장 큰 행성은 무엇인가요?'})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Fv7V1cmE6SWK",
        "outputId": "7694f69b-9079-449e-b9b5-e711c643ce05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'태양계에서 가장 큰 행성은 목성입니다. 목성은 지름이 약 142,984km로 태양계에서 가장 큰 지름을 가진 행성입니다.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Model Parameter <br>\n",
        "1) 모델 클래스 유형 <br>\n"
      ],
      "metadata": {
        "id": "aOPbmHXA8aKy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "LLM"
      ],
      "metadata": {
        "id": "AiBC7_Zx8jhk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import OpenAI\n",
        "llm = OpenAI()\n",
        "\n",
        "llm.invoke(\"한국의 대표적인 관광지 3군데를 추천해주세요.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "5AxX7teo6SUL",
        "outputId": "bc1f14b7-63e9-4197-cf78-940c9878847a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\n1. 경복궁 - 서울에 위치한 조선 시대 왕의 궁전으로, 아름다운 전통 한옥 건물과 화려한 궁궐을 볼 수 있으며 한국의 역사와 문화를 체험할 수 있는 곳입니다.\\n\\n2. 제주도 - 한국의 남쪽에 위치한 도시로, 아름다운 자연 경관과 다양한 관광 명소를 제공하고 있습니다. 특히 한라산, 우도, 성산일출봉 등이 인기 있는 관광지입니다.\\n\\n3. 부산 해운대해수욕장 - 부산에 위치한 해수욕장으로, 깨끗한 백사장과 아름다운 해안 라인이 인기 있는 관광 명소입니다. 해수욕뿐만 아니라 다양한 레스토'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ChatModel"
      ],
      "metadata": {
        "id": "EhLiRq8e8u77"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "chat = ChatOpenAI()\n",
        "\n",
        "chat_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"이 시스템은 여행 전문가입니다.\"),\n",
        "    (\"user\", \"{user_input}\"),\n",
        "])\n",
        "\n",
        "chain = chat_prompt | chat | output_parser\n",
        "\n",
        "chain.invoke({'user_input':'한국의 대표적인 관광지 3군데를 추천해주세요.'})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "id": "KXP-2AQH6SSS",
        "outputId": "7ba4c5ce-d781-417d-9a65-03afcf5b953c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'한국의 대표적인 관광지로는 다음 세 곳을 추천드립니다:\\n\\n1. 경복궁 (Gyeongbokgung Palace) - 서울에 위치한 경복궁은 조선 시대의 궁궐로, 한국의 역사와 전통을 경험할 수 있는 곳입니다. 아름다운 건물과 정원, 전통적인 복식을 입은 경비병들을 볼 수 있습니다.\\n\\n2. 부산 해운대해수욕장 (Haeundae Beach) - 부산의 대표적인 해변으로, 맑은 바다와 긴 백사장이 아름다운 곳입니다. 여름에는 많은 사람들이 모여 즐기는 해변으로, 다양한 레스토랑과 상점도 많이 있습니다.\\n\\n3. 경주 (Gyeongju) - 경주는 한국의 역사와 문화가 살아 숨쉬는 도시로, 많은 유적지와 문화유산이 있는 곳입니다. 석가탑, 첨성대, 안압지 등의 유명한 관광지뿐만 아니라, 아름다운 자연 풍경도 즐길 수 있습니다.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Message 이용"
      ],
      "metadata": {
        "id": "ZvWNO7Dx9SHU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
        "\n",
        "chat = ChatOpenAI()\n",
        "chat_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        SystemMessagePromptTemplate.from_template(\"이 시스템은 여행 전문가입니다,\"),\n",
        "        HumanMessagePromptTemplate.from_template(\"{user_input}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "chain = chat_prompt | chat | output_parser\n",
        "\n",
        "chain.invoke({'user_input':'한국의 대표적인 관광지 3군데를 추천해주세요.'})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "id": "_h5igRII6SQT",
        "outputId": "bdfaf2db-5995-40f5-f41a-6385cd11e378"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'한국의 대표적인 관광지로는 다음 3군데를 추천드립니다:\\n\\n1. 경복궁 (Gyeongbokgung Palace): 서울에 위치한 경복궁은 조선 왕조의 궁궐로, 한국의 역사와 전통을 경험할 수 있는 곳입니다. 경내에는 다양한 궁궐 건물과 정원이 있어 한국의 아름다운 건축물과 문화를 감상할 수 있습니다.\\n\\n2. 제주도 (Jeju Island): 한국의 대표적인 관광지인 제주도는 아름다운 자연 풍경과 풍부한 문화를 경험할 수 있는 곳입니다. 화산암으로 이루어진 풍부한 자연경관과 맑은 바다, 그리고 독특한 문화와 음식을 즐길 수 있습니다.\\n\\n3. 부산 해운대해수욕장 (Haeundae Beach, Busan): 부산의 대표적인 해변인 해운대해수욕장은 깨끗한 백사장과 아름다운 일몰을 감상할 수 있는 인기 관광지입니다. 여름에는 해수욕과 해변에서의 여가를 즐기는 사람들로 북적이는 곳이기도 합니다.\\n\\n이 세 곳은 한국을 대표하는 관광지로서 자연과 역사, 문화를 모두 경험할 수 있는 장소들입니다.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2)모델 파라미터 설정"
      ],
      "metadata": {
        "id": "E-rnGhBN-KN5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델에 직접 파라미터를 전달(모델 생성 시점)\n"
      ],
      "metadata": {
        "id": "Jbnmoca2-NKb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "#모델 파라미터 설정\n",
        "params = {\n",
        "    \"temperature\" : 0.7, #생성된 텍스트의 다양성 조정\n",
        "    \"max_tokens\" : 100, #생성할 최대 토큰 수\n",
        "}\n",
        "\n",
        "kwargs = {\n",
        "    \"frequency_penalty\" : 0.5, #빈도 패널티 (이미 등장한 단어의 재등장 확률 조정)\n",
        "    \"presence_penalty\" : 0.5, #존재 패널티 (새로운 단어의 도입을 장려)\n",
        "    \"stop\" : [\"\\n\"] #정지 시퀀스 설정\n",
        "}\n",
        "\n",
        "#모델 인스턴스를 생성 할 때 설정\n",
        "model = ChatOpenAI(model = 'gpt-3.5-turbo-0125', **params, **kwargs)\n",
        "\n",
        "# 모델 호출\n",
        "question = \"태양계에서 가장 큰 행성은 무엇인가요?\"\n",
        "response = model.invoke(input=question)\n",
        "\n",
        "# 전체 응답 출력\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PszlioSJ9u21",
        "outputId": "8a2edee2-1b75-4293-ac9b-c73c49e2b780"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "content='태양계에서 가장 큰 행성은 목성입니다. 목성은 태양계 내에서 가장 크고 질량도 가장 많이 갖춘 행성으로 알려져 있습니다.' response_metadata={'token_usage': {'completion_tokens': 62, 'prompt_tokens': 29, 'total_tokens': 91}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-eaf56841-0b02-406b-891d-e548ab6824c1-0' usage_metadata={'input_tokens': 29, 'output_tokens': 62, 'total_tokens': 91}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델에 직접 파라미터를 전달(모델 호출 시점)"
      ],
      "metadata": {
        "id": "rnSl8EiVAb5e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "params = {\n",
        "    \"temperature\" : 0.7, #생성된 텍스트의 다양성 조정\n",
        "    \"max_tokens\" : 10, #생성할 최대 토큰 수\n",
        "}\n",
        "\n",
        "response = model.invoke(input=question, **params)\n",
        "\n",
        "# 전체 응답 출력\n",
        "print(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWpnlaNK9uyQ",
        "outputId": "f3be6832-4f99-429e-aba0-14aa7604f305"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "태양계에서 가장 큰\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델에 추가적인 파라미터를 전달\n",
        "- bind 메서드 사용\n"
      ],
      "metadata": {
        "id": "V7kMp5EpApFT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"이 시스템은 천문학 질문에 답변할 수 있습니다.\"),\n",
        "    (\"user\", \"{user_input}\"),\n",
        "])\n",
        "\n",
        "model = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", max_tokens=100)\n",
        "\n",
        "messages = prompt.format_messages(user_input=\"태양계에서 가장 큰 행성은 무엇인가요?\")\n",
        "\n",
        "before_answer = model.invoke(messages)\n",
        "\n",
        "# # binding 이전 출력\n",
        "print(before_answer)\n",
        "\n",
        "# 모델 호출 시 추가적인 인수를 전달하기 위해 bind 메서드 사용 (응답의 최대 길이를 10 토큰으로 제한)\n",
        "chain = prompt | model.bind(max_tokens=10)\n",
        "\n",
        "after_answer = chain.invoke({\"user_input\": \"태양계에서 가장 큰 행성은 무엇인가요?\"})\n",
        "\n",
        "# binding 이후 출력\n",
        "print(after_answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CGW_SCXmAlQP",
        "outputId": "fb9b1e78-3222-4ea2-abc8-53e4c092337d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "content='태양계에서 가장 큰 행성은 목성입니다. 목성은 지름이 약 142,984km로, 태양계에서 가장 큰 행성이며 지름이 가장 큽니다.' response_metadata={'token_usage': {'completion_tokens': 61, 'prompt_tokens': 58, 'total_tokens': 119}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-4feeff09-6b4f-498a-af98-1a7a6e6345da-0' usage_metadata={'input_tokens': 58, 'output_tokens': 61, 'total_tokens': 119}\n",
            "content='태양계에서 가장 큰' response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 58, 'total_tokens': 68}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'length', 'logprobs': None} id='run-c52dd33b-20c5-4173-9f46-2ca813731cb7-0' usage_metadata={'input_tokens': 58, 'output_tokens': 10, 'total_tokens': 68}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Output Parsers"
      ],
      "metadata": {
        "id": "_4gPxJ_SBX3y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1)CSV Parser"
      ],
      "metadata": {
        "id": "3sU9V5_kBbUM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.output_parsers import CommaSeparatedListOutputParser\n",
        "\n",
        "output_parser = CommaSeparatedListOutputParser()\n",
        "format_instructions = output_parser.get_format_instructions()\n",
        "\n",
        "print(format_instructions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R6pMEUZpBZ9g",
        "outputId": "5a0bea4b-6bf4-4b3e-b5e4-e9c6873354d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your response should be a list of comma separated values, eg: `foo, bar, baz` or `foo,bar,baz`\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    template=\"List five {subject}.\\n{format_instructions}\",\n",
        "    input_variables=[\"subject\"],\n",
        "    partial_variables={\"format_instructions\": format_instructions},\n",
        ")\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0)\n",
        "\n",
        "chain = prompt | llm | output_parser\n",
        "\n",
        "chain.invoke({\"subject\": \"popular Korean cusine\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Ku4lkEoBqbD",
        "outputId": "40dacfa2-9930-4a6d-9105-33b9c4bdcb8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Bibimbap', 'Kimchi', 'Bulgogi', 'Japchae', 'Tteokbokki']"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2)Json Parser"
      ],
      "metadata": {
        "id": "Y2QYRNa5B4ly"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.output_parsers import JsonOutputParser\n",
        "from langchain_core.pydantic_v1 import BaseModel, Field\n",
        "\n",
        "#자료구조 정의 (pydantic)\n",
        "class CusineRecipe(BaseModel):\n",
        "    name : str = Field(description=\"name of a cusine\")\n",
        "    recipe : str = Field(description=\"recipe of a cusine\")"
      ],
      "metadata": {
        "id": "YUpbN-cnB6O6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#출력 파서 정의\n",
        "output_parser = JsonOutputParser(pydantic_object=CusineRecipe)\n",
        "\n",
        "format_instructions = output_parser.get_format_instructions()\n",
        "\n",
        "print(format_instructions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jvxvomDNCSHy",
        "outputId": "4a9e0d48-77a0-43dd-f150-1803c6e41088"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
            "\n",
            "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
            "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
            "\n",
            "Here is the output schema:\n",
            "```\n",
            "{\"properties\": {\"name\": {\"title\": \"Name\", \"description\": \"name of a cusine\", \"type\": \"string\"}, \"recipe\": {\"title\": \"Recipe\", \"description\": \"recipe of a cusine\", \"type\": \"string\"}}, \"required\": [\"name\", \"recipe\"]}\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt 구성\n",
        "prompt = PromptTemplate(\n",
        "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
        "    input_variables=[\"query\"],\n",
        "    partial_variables={\"format_instructions\": format_instructions},\n",
        ")\n",
        "\n",
        "print(prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SwsWEL5bCi7E",
        "outputId": "6d7aa843-5439-4ac4-e037-cad1f159966c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_variables=['query'] partial_variables={'format_instructions': 'The output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\"properties\": {\"name\": {\"title\": \"Name\", \"description\": \"name of a cusine\", \"type\": \"string\"}, \"recipe\": {\"title\": \"Recipe\", \"description\": \"recipe of a cusine\", \"type\": \"string\"}}, \"required\": [\"name\", \"recipe\"]}\\n```'} template='Answer the user query.\\n{format_instructions}\\n{query}\\n'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "chain = prompt | model | output_parser\n",
        "\n",
        "chain.invoke({\"query\": \"Let me know how to cook Bibimbap\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GYDvRLorCrlb",
        "outputId": "ab311fd9-097d-4268-c0c9-5d518c181cb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'name': 'Bibimbap',\n",
              " 'recipe': 'Bibimbap is a Korean mixed rice dish that is typically made with white rice, vegetables, meat, and a spicy sauce. To cook Bibimbap, start by cooking white rice according to package instructions. In a skillet, cook vegetables such as spinach, carrots, bean sprouts, and mushrooms separately with a little oil and seasoning. Cook thinly sliced beef in a hot skillet with soy sauce and garlic. In'}"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    }
  ]
}