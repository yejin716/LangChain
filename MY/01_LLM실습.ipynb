{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BUFad8we6KNA",
        "outputId": "ee5b136e-da44-4309-be4b-a4cfb05e4320"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.35.15-py3-none-any.whl (328 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m328.6/328.6 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.7.4)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.20.1)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.35.15\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.2.9-py3-none-any.whl (987 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m987.7/987.7 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.31)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting langchain-core<0.3.0,>=0.2.20 (from langchain)\n",
            "  Downloading langchain_core-0.2.21-py3-none-any.whl (372 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m372.0/372.0 kB\u001b[0m \u001b[31m47.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.2.2-py3-none-any.whl (25 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
            "  Downloading langsmith-0.1.92-py3-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.0/135.0 kB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.5.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.3.0,>=0.2.20->langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.20->langchain) (24.1)\n",
            "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Downloading orjson-3.10.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.20.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.7.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.20->langchain)\n",
            "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Installing collected packages: orjson, jsonpointer, jsonpatch, langsmith, langchain-core, langchain-text-splitters, langchain\n",
            "Successfully installed jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.2.9 langchain-core-0.2.21 langchain-text-splitters-0.2.2 langsmith-0.1.92 orjson-3.10.6\n",
            "Collecting langchain_openai\n",
            "  Downloading langchain_openai-0.1.17-py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.7/46.7 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: langchain-core<0.3.0,>=0.2.20 in /usr/local/lib/python3.10/dist-packages (from langchain_openai) (0.2.21)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.32.0 in /usr/local/lib/python3.10/dist-packages (from langchain_openai) (1.35.15)\n",
            "Collecting tiktoken<1,>=0.7 (from langchain_openai)\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.20->langchain_openai) (6.0.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.20->langchain_openai) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.75 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.20->langchain_openai) (0.1.92)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.20->langchain_openai) (24.1)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.20->langchain_openai) (2.8.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.20->langchain_openai) (8.5.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.32.0->langchain_openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.32.0->langchain_openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.32.0->langchain_openai) (0.27.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.32.0->langchain_openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.32.0->langchain_openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.32.0->langchain_openai) (4.12.2)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.5.15)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2.31.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.32.0->langchain_openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.32.0->langchain_openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.32.0->langchain_openai) (2024.7.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.32.0->langchain_openai) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.32.0->langchain_openai) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.20->langchain_openai) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3.0,>=0.2.20->langchain_openai) (3.10.6)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.3.0,>=0.2.20->langchain_openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.3.0,>=0.2.20->langchain_openai) (2.20.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (2.0.7)\n",
            "Installing collected packages: tiktoken, langchain_openai\n",
            "Successfully installed langchain_openai-0.1.17 tiktoken-0.7.0\n",
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.2.7-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m40.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.0.31)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (3.9.5)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: langchain<0.3.0,>=0.2.7 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.2.9)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.12 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.2.21)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.1.92)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (1.25.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.31.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (8.5.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading marshmallow-3.21.3-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.7->langchain_community) (0.2.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.7->langchain_community) (2.8.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.12->langchain_community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.12->langchain_community) (24.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain_community) (3.10.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2024.7.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.0.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.12->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.7->langchain_community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.7->langchain_community) (2.20.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, typing-inspect, dataclasses-json, langchain_community\n",
            "Successfully installed dataclasses-json-0.6.7 langchain_community-0.2.7 marshmallow-3.21.3 mypy-extensions-1.0.0 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "# #필수 라이브러리 설치 및 로드\n",
        "!pip install openai\n",
        "!pip install langchain\n",
        "!pip install langchain_openai\n",
        "!pip install langchain_community"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "BjbLs9PE6Qx7"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import openai\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"api key 입력하세요\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "dEJi9adv-SvT",
        "outputId": "510ae4bc-55d9-4df3-9f55-77d8a42026a2"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n\\n파이썬은 인기 있는 프로그래밍 언어인 이유가 다양합니다. 먼저, 파이썬은 배우기 쉽고 읽기 쉽습니다. 그래서 초보자들도 쉽게 배울 수 있고, 코드를 이해하기 쉽고 수정하기도 쉽습니다. 또한 파이썬은 다양한 분야에서 사용되는 범용 언어로서, 데이터 분석, 인공지능, 웹 개발 등 다양한 분야에서 활용할 수 있습니다. 또한 파이썬은 오픈 소스 언어로서 무료로 이용할 수 있기 때문에 많은 사람들이 사용하고 있습니다. 또한 파이썬은 강력한 라이브러리와 프레임워크를 제공하고 있어서 빠르고 효율적인 개'"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain.llms import OpenAI\n",
        "\n",
        "llm = OpenAI()\n",
        "llm.predict('why python is the most popular language? answer in Korean')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tDWKE06A7YKV",
        "outputId": "eb7fe0c4-a4c1-43cf-fb5d-c68f55d0f240"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
            "  warn_deprecated(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The method `BaseChatModel.predict` was deprecated in langchain-core 0.1.7 and will be removed in 0.3.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "파이썬이 가장 인기 있는 언어인 이유는 다음과 같습니다:\n",
            "\n",
            "1. 문법이 간단하고 읽기 쉽기 때문에 초보자도 쉽게 배울 수 있습니다.\n",
            "2. 다양한 라이브러리와 프레임워크를 제공하여 다양한 용도로 활용할 수 있습니다.\n",
            "3. 데이터 과학 및 인공지능 분야에서 널리 사용되는데, 이는 빠른 개발과 실험을 가능하게 합니다.\n",
            "4. 커뮤니티가 활발하고 지속적으로 업데이트되는 언어이기 때문에 신뢰성이 높습니다.\n",
            "5. 다양한 플랫폼과 운영체제에서 사용할 수 있어서 유연하게 활용할 수 있습니다.\n"
          ]
        }
      ],
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "chatgpt = ChatOpenAI(model_name = 'gpt-3.5-turbo')\n",
        "answer = chatgpt.predict('why python is the most popular language? answer in Korean')\n",
        "print(answer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9VlM-u-_Q2D"
      },
      "source": [
        "매개변수 조절해보기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZoJFze_A-7C7",
        "outputId": "7760a4fb-579a-46a5-a3bd-472f93357897"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "파이썬이 가장 인기 있는 언어인 이유는 다음과 같습니다:\n",
            "\n",
            "1. 쉽고 간결한 문법: 파이썬은 다른 프로그래밍 언어에 비해 문법이 간결하고 쉽기 때문에 입문자들도 쉽게 배울 수 있습니다.\n",
            "\n",
            "2. 다양한 용도: 파이썬은 데이터 분석, 인공지능, 웹 개발 등 다양한 분야에서 사용되기 때문에 많은 사람들이 관심을 갖고 있습니다.\n",
            "\n",
            "3. 커뮤니티 지원: 파이썬은 활발한 커뮤니티를 가지고 있어서 사용자들이 서로 도움을 주고 받을 수 있습니다.\n",
            "\n",
            "4. 라이브러리와 프레임워크: 파이썬은 다양한 라이브러리와 프레임워크를 제공하여 개발을 더욱 편리하게 할 수 있습니다.\n",
            "\n",
            "이러한 이유들로 인해 파이썬은 가장 인기 있는 프로그래밍 언어 중 하나로 자리 잡았습니다.\n"
          ]
        }
      ],
      "source": [
        "chatgpt = ChatOpenAI(model_name = 'gpt-3.5-turbo', temperature = 0) # temperature 0 >> 일관성 1 >> 창의성\n",
        "answer = chatgpt.predict('why python is the most popular language? answer in Korean')\n",
        "print(answer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QW0l7gPK_O5W",
        "outputId": "b6140179-326e-4277-c50d-ac7bd0eae7a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "파이썬이 가장 인기 있는 언어인 이유는 다양한 이유가 있습니다. 먼저 파이썬은 배우기 쉽고 사용하기 편리한 언어이기 때문에 초보자들도 쉽게 접근할 수 있습니다. 또한 파이썬은 다양한 분야에서 사용되며 데이터 과학, 인공지능, 웹 개발 등 다양한 분야에서 유용하게 활용될 수 있습니다. 또한 파이썬은 라이브러리와 프레임워크가 풍부하며 커뮤니티가 활발하게 활동하고 있어 개발자들이 문제를 해결하고 지식을 공유하기 쉽습니다. 이러한 이유들로 인해 파이썬은 가장 인기 있는 언어 중 하나로 자리잡게 되었습니다.\n"
          ]
        }
      ],
      "source": [
        "chatgpt = ChatOpenAI(model_name = 'gpt-3.5-turbo', temperature = 1) # temperature 0 >> 일관성 / 1 >> 창의성\n",
        "answer = chatgpt.predict('why python is the most popular language? answer in Korean')\n",
        "print(answer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tqHQR_AzAdbN"
      },
      "source": [
        "타이핑 하듯 결과 (StreamingStdOutCallbackHandler)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rOM1wjzQ_O1f",
        "outputId": "598bed12-5295-4bba-f119-c09e8e42dae1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
            "  warn_deprecated(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The method `BaseChatModel.predict` was deprecated in langchain-core 0.1.7 and will be removed in 0.3.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "파이썬은 많은 이유로 인해 가장 인기 있는 프로그래밍 언어 중 하나입니다. \n",
            "\n",
            "첫째, 파이썬은 문법이 간단하고 읽기 쉬워 초보자에게 적합합니다. 또한 다양한 분야에서 사용되는 범용 언어로서 데이터 과학, 인공지능, 웹 개발 등 다양한 분야에서 활용되고 있습니다.\n",
            "\n",
            "둘째, 파이썬은 무료로 사용할 수 있으며 오픈소스 커뮤니티가 활발하게 운영되어 다양한 라이브러리와 패키지를 제공합니다. 이를 통해 개발 시간을 단축하고 효율적으로 작업할 수 있습니다.\n",
            "\n",
            "셋째, 파이썬은 크로스 플랫폼 언어로서 Windows, macOS, Linux 등 다양한 환경에서 사용할 수 있습니다. 또한 강력한 커뮤니티 지원과 높은 생산성을 자랑하여 많은 개발자들이 파이썬을 선호하는 이유입니다."
          ]
        }
      ],
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
        "\n",
        "chatgpt = ChatOpenAI(model_name = 'gpt-3.5-turbo', streaming=True, callbacks=[StreamingStdOutCallbackHandler()], temperature = 1) # temperature 0 >> 일관성 1 >> 창의성\n",
        "answer = chatgpt.predict('why python is the most popular language? answer in Korean')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4Yy32Hk_OzE",
        "outputId": "1b794ae1-4017-4fd4-f36e-1f21f6af1619"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The method `BaseChatModel.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 0.3.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "content='나는 프로그래밍을 좋아해요.' response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 25, 'total_tokens': 39}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-d1f6dc78-a894-4784-b247-234c0c6f467e-0'\n"
          ]
        }
      ],
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.schema import AIMessage, HumanMessage, SystemMessage\n",
        "\n",
        "#systemMessage >> 챗봇의 역할을 부여\n",
        "#HumanMessage >> 사용자가 보내는 메시지\n",
        "#AIMessage >> 답변\n",
        "chatgpt = ChatOpenAI(model_name='gpt-3.5-turbo', temperature = 0)\n",
        "\n",
        "messages = [\n",
        "    SystemMessage(\n",
        "        content = \"You are a helpful assistant that translates English to Korean.\"\n",
        "    ),\n",
        "    HumanMessage(\n",
        "        content = \"I love programming\"\n",
        "    ),\n",
        "]\n",
        "response = chatgpt(messages)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "F5xeGA0oGjLE",
        "outputId": "4791a40c-1122-429f-a9c2-66672702dbe9"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'나는 프로그래밍을 좋아해요.'"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UkfrJDzfGmuK",
        "outputId": "48cab944-a10c-407b-e72d-6aecf61b09a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "좋습니다! Large Language Model 학습을 위한 공부 계획을 세워보겠습니다.\n",
            "\n",
            "**1. 기본 개념 이해**\n",
            "- Large Language Model의 개념과 원리에 대해 학습해보세요.\n",
            "- 자연어 처리의 기초 이론을 이해하는 것이 중요합니다.\n",
            "\n",
            "**2. 모델 구조 파악**\n",
            "- Large Language Model의 주요 구성 요소와 작동 방식을 공부해보세요.\n",
            "- Transformer와 BERT와 같은 대표적인 모델의 구조를 숙지해야 합니다.\n",
            "\n",
            "**3. 학습 데이터 이해**\n",
            "- Large Language Model 학습을 위해 사용되는 데이터셋에 대해 조사해보세요.\n",
            "- Pre-training, Fine-tuning 등의 과정에 대해 이해하고 실제 데이터셋을 살펴보세요.\n",
            "\n",
            "**4. 최신 연구 트렌드**\n",
            "- 최근 Large Language Model 분야의 연구 동향과 주요 논문들을 살펴보세요.\n",
            "- GPT-3, T5, XLNet 등의 최신 모델에 대한 이해도를 높이세요.\n",
            "\n",
            "**5. 실습과 프로젝트**\n",
            "- Large Language Model을 활용한 실습과 프로젝트를 진행해보세요.\n",
            "- Hugging Face Transformers와 같은 라이브러리를 사용하여 실제 활용 방법을 익혀보세요.\n",
            "\n",
            "위의 단계를 순서대로 공부하시면 Large Language Model에 대한 폭넓은 이해와 숙련도를 쌓을 수 있을 것입니다. 어떠한 도움이 필요하시다면 언제든지 물어보세요!"
          ]
        }
      ],
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.schema import AIMessage, HumanMessage, SystemMessage\n",
        "\n",
        "chat = ChatOpenAI(model_name='gpt-3.5-turbo', streaming=True, callbacks=[StreamingStdOutCallbackHandler()], temperature = 1)\n",
        "answer = chat(\n",
        "    [\n",
        "        SystemMessage(content = '당신은 공부 계획을 세워주는 스터디 플래너 머신입니다. 사용자의 공부 주제를 입력 받으면, 이를 학습하기 위한 공부 계획을 작성합니다.'),\n",
        "        HumanMessage(content = 'Large Language Model에 대해서 공부하고 싶어요.')\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q7zqHEuNHa4L",
        "outputId": "0e2b0e6e-9b8c-4355-e18d-a59484886b20"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='좋습니다! Large Language Model 학습을 위한 공부 계획을 세워보겠습니다.\\n\\n**1. 기본 개념 이해**\\n- Large Language Model의 개념과 원리에 대해 학습해보세요.\\n- 자연어 처리의 기초 이론을 이해하는 것이 중요합니다.\\n\\n**2. 모델 구조 파악**\\n- Large Language Model의 주요 구성 요소와 작동 방식을 공부해보세요.\\n- Transformer와 BERT와 같은 대표적인 모델의 구조를 숙지해야 합니다.\\n\\n**3. 학습 데이터 이해**\\n- Large Language Model 학습을 위해 사용되는 데이터셋에 대해 조사해보세요.\\n- Pre-training, Fine-tuning 등의 과정에 대해 이해하고 실제 데이터셋을 살펴보세요.\\n\\n**4. 최신 연구 트렌드**\\n- 최근 Large Language Model 분야의 연구 동향과 주요 논문들을 살펴보세요.\\n- GPT-3, T5, XLNet 등의 최신 모델에 대한 이해도를 높이세요.\\n\\n**5. 실습과 프로젝트**\\n- Large Language Model을 활용한 실습과 프로젝트를 진행해보세요.\\n- Hugging Face Transformers와 같은 라이브러리를 사용하여 실제 활용 방법을 익혀보세요.\\n\\n위의 단계를 순서대로 공부하시면 Large Language Model에 대한 폭넓은 이해와 숙련도를 쌓을 수 있을 것입니다. 어떠한 도움이 필요하시다면 언제든지 물어보세요!', response_metadata={'finish_reason': 'stop'}, id='run-00e497df-3622-4f5e-bfe9-913496102232-0')"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#chatGPT의 대답은 AIMessage라는 딕셔너리 형태로 제공한다.\n",
        "answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "id": "4UXhaO89HnmR",
        "outputId": "2034e0de-fc93-42ff-f49f-392841140f6b"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'좋습니다! Large Language Model 학습을 위한 공부 계획을 세워보겠습니다.\\n\\n**1. 기본 개념 이해**\\n- Large Language Model의 개념과 원리에 대해 학습해보세요.\\n- 자연어 처리의 기초 이론을 이해하는 것이 중요합니다.\\n\\n**2. 모델 구조 파악**\\n- Large Language Model의 주요 구성 요소와 작동 방식을 공부해보세요.\\n- Transformer와 BERT와 같은 대표적인 모델의 구조를 숙지해야 합니다.\\n\\n**3. 학습 데이터 이해**\\n- Large Language Model 학습을 위해 사용되는 데이터셋에 대해 조사해보세요.\\n- Pre-training, Fine-tuning 등의 과정에 대해 이해하고 실제 데이터셋을 살펴보세요.\\n\\n**4. 최신 연구 트렌드**\\n- 최근 Large Language Model 분야의 연구 동향과 주요 논문들을 살펴보세요.\\n- GPT-3, T5, XLNet 등의 최신 모델에 대한 이해도를 높이세요.\\n\\n**5. 실습과 프로젝트**\\n- Large Language Model을 활용한 실습과 프로젝트를 진행해보세요.\\n- Hugging Face Transformers와 같은 라이브러리를 사용하여 실제 활용 방법을 익혀보세요.\\n\\n위의 단계를 순서대로 공부하시면 Large Language Model에 대한 폭넓은 이해와 숙련도를 쌓을 수 있을 것입니다. 어떠한 도움이 필요하시다면 언제든지 물어보세요!'"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#content를 key값으로 호출하여 text만 출력할수 있다.\n",
        "answer.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x3xYAGEXHnkP"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RZLSRDnTHnid"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
